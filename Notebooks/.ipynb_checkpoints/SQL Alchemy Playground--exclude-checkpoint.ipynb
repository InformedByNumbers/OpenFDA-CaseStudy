{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import Integer, Text, String, Float\n",
    "#import psycopg2\n",
    "\n",
    "loaded_files_and_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_DB_URI(db_type, db_lib, user_id, password, db_name,  db_location='localhost', port='5432' ):\n",
    "    '''\n",
    "        A method which generates a DB_URI for SQL-Alchemey. Assumption that this will be\n",
    "        used with Postgresql, however written to be generic.\n",
    "\n",
    "        arg:\n",
    "\n",
    "        db_type     --> the type of database, e.g 'postgres', 'mysql'\n",
    "\n",
    "        db_lib      --> the appropriate sql-alchemy plughin for \n",
    "                        db_type, e.g 'psycopg2' or 'pymysql'\n",
    "\n",
    "        user_id     --> the user name for the database, who has \n",
    "                        appropriate permissions\n",
    "\n",
    "        password    --> the password for the db-user-id.\n",
    "        db_name     --> the name of the db, e.g. 'esomeprazole'\n",
    "        db_location --> the address / URL for the database. DEFAULT = localhost\n",
    "        port        --> the port for the database. DEFAULT = 5432\n",
    "        \n",
    "        returns:\n",
    "        db_URI     --> The URI for SQL-Alchemy of the form:\n",
    "                       postgres+psycop2://user_id:password@db_location:5432/db_name\n",
    "\n",
    "    '''\n",
    "    \n",
    "    db_URI = db_type+'+'+db_lib+'://'+user_id+':'+password+'@'+db_location+':'+port+'/'+db_name\n",
    "\n",
    "    return db_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_file_as_df(data_file_path, file_name):\n",
    "    \n",
    "    df = pd.read_csv(data_file_path+file_name)\n",
    "    new_columns = [column.replace(' ', '_').lower() for column in df]\n",
    "    df.columns = new_columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_cols(df):\n",
    "    '''\n",
    "    A method which converts the col-dtype from Pandas/Numpy \n",
    "    to the SQLAlchemy equivelent. \n",
    "    args:\n",
    "    \n",
    "    df ---> A pandas DataFrame\n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    db_cols --> a dictionary with column-name as key and SQL-Alchemy\n",
    "                data type as values.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    col_info = dict(df.dtypes)\n",
    "    db_cols = {}\n",
    "    for k in col_info:\n",
    "\n",
    "        if col_info[k] == 'object':\n",
    "            db_cols[k] = String\n",
    "\n",
    "        elif col_info[k] == 'int64':\n",
    "            db_cols[k] = Integer\n",
    "\n",
    "        elif col_info[k] == 'float64':\n",
    "            db_cols[k] = Float  \n",
    "        else:\n",
    "            print('Unaccounted for type:')\n",
    "            print(k, col_info[k])\n",
    "            return None\n",
    "    return db_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(data_file_path, file_name_pattern):\n",
    "\n",
    "    all_file_list = os.listdir(data_file_path)\n",
    "\n",
    "    all_file_list.sort()\n",
    "    \n",
    "    file_list = []\n",
    "\n",
    "    for f in all_file_list:\n",
    "        \n",
    "        if file_name_pattern in f:\n",
    "            file_list.append(f)\n",
    "       \n",
    "    return  file_list       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_csv_data_to_db(filename_pattern_and_tablename_dict, data_file_path):\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    print('outside first for')\n",
    "    # 1. iterate through list of patterns, to load all file-types into the database.\n",
    "    for pattern in filename_pattern_and_tablename_dict.keys():\n",
    "                      \n",
    "        # 2. Get the list of files from the data-folder:\n",
    "        data_file_list = get_file_names(data_file_path, pattern)\n",
    "       \n",
    "        \n",
    "        table_name = filename_pattern_and_tablename_dict[pattern]\n",
    "                \n",
    "        # 3. load data into a data frame\n",
    "        file_counter = 1\n",
    "        print('in first loop, outside second.. ')\n",
    "        for data_file in data_file_list:\n",
    "            print('top of second loop.')\n",
    "            df = load_csv_file_as_df(data_file_path, data_file)\n",
    "\n",
    "            # Get the columns data types from the data frame and convert \n",
    "            # to SQL-Alchemy friend types.\n",
    "\n",
    "            db_cols = get_db_cols(df)\n",
    "            \n",
    "            if db_cols == None:\n",
    "                \n",
    "                print(data_file, f)\n",
    "                return None\n",
    "\n",
    "            if file_counter == 1:\n",
    "                \n",
    "                df.to_sql(table_name,\n",
    "                                   db_engine,\n",
    "                                   if_exists='replace',\n",
    "                                   schema='public',\n",
    "                                   index=False,\n",
    "                                   chunksize=1000,\n",
    "                                   dtype=db_cols)            \n",
    "                print('here, counter 1')\n",
    "                break\n",
    "                \n",
    "            if file_counter > 1:\n",
    "                \n",
    "                df.to_sql(table_name,\n",
    "                                   db_engine,\n",
    "                                   if_exists='append',\n",
    "                                   schema='public',\n",
    "                                   index=False,\n",
    "                                   chunksize=1000,\n",
    "                                   dtype=db_cols)   \n",
    "                \n",
    "            file_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-05 21:24:33,586 INFO sqlalchemy.engine.base.Engine select version()\n",
      "2020-05-05 21:24:33,586 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-05-05 21:24:33,589 INFO sqlalchemy.engine.base.Engine select current_schema()\n",
      "2020-05-05 21:24:33,589 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-05-05 21:24:33,592 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-05-05 21:24:33,594 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-05-05 21:24:33,595 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-05-05 21:24:33,596 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-05-05 21:24:33,597 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n",
      "2020-05-05 21:24:33,598 INFO sqlalchemy.engine.base.Engine {}\n"
     ]
    }
   ],
   "source": [
    "db_type = 'postgres'\n",
    "db_lib = 'psycopg2'\n",
    "user_id = 'bhima'\n",
    "password= ''\n",
    "db_name = 'openfda'\n",
    "\n",
    "db_URI = build_DB_URI(db_type, db_lib, user_id, password, db_name)\n",
    "db_engine = create_engine(db_URI, echo=True)\n",
    "db_engine.connect()\n",
    "connection= db_engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outside first for\n",
      "in first loop, outside second.. \n",
      "top of second loop.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'drugs_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-04386204097e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../Data/csv/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mload_csv_data_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_pattern_and_tablename_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-e9fa490cd30c>\u001b[0m in \u001b[0;36mload_csv_data_to_db\u001b[0;34m(filename_pattern_and_tablename_dict, data_file_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_file_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'top of second loop.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv_file_as_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Get the columns data types from the data frame and convert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-c17d308a22b6>\u001b[0m in \u001b[0;36mload_csv_file_as_df\u001b[0;34m(data_file_path, file_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnew_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdrugs_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'drugs_df' is not defined"
     ]
    }
   ],
   "source": [
    "filename_pattern_and_tablename_dict = {'drug.csv':'drugs', 'patient.csv':'patients', \\\n",
    "                      'reaction.csv':'reactions', 'open_fda.csv':'open_fda'}\n",
    "\n",
    "#location of the data files:\n",
    "data_file_path = '../Data/csv/'\n",
    "\n",
    "load_csv_data_to_db(filename_pattern_and_tablename_dict, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
