{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import Integer, Text, String, Float, DateTime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_DB_URI(db_type, db_lib, user_id, password, db_name,  db_location='localhost', port='5432' ):\n",
    "    '''\n",
    "        A method which generates a DB_URI for SQL-Alchemey. Assumption that this will be\n",
    "        used with Postgresql, however written to be generic.\n",
    "\n",
    "        arg:\n",
    "\n",
    "        db_type     --> the type of database, e.g 'postgres', 'mysql'\n",
    "\n",
    "        db_lib      --> the appropriate sql-alchemy plughin for \n",
    "                        db_type, e.g 'psycopg2' or 'pymysql'\n",
    "\n",
    "        user_id     --> the user name for the database, who has \n",
    "                        appropriate permissions\n",
    "\n",
    "        password    --> the password for the db-user-id.\n",
    "        db_name     --> the name of the db, e.g. 'esomeprazole'\n",
    "        db_location --> the address / URL for the database. DEFAULT = localhost\n",
    "        port        --> the port for the database. DEFAULT = 5432\n",
    "        \n",
    "        returns:\n",
    "        db_URI     --> The URI for SQL-Alchemy of the form:\n",
    "                       postgres+psycop2://user_id:password@db_location:5432/db_name\n",
    "\n",
    "    '''\n",
    "    \n",
    "    db_URI = db_type+'+'+db_lib+'://'+user_id+':'+password+'@'+db_location+':'+port+'/'+db_name\n",
    "\n",
    "    return db_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_cols(df):\n",
    "    '''\n",
    "    A method which converts the col-dtype from Pandas/Numpy \n",
    "    to the SQLAlchemy equivelent. \n",
    "    args:\n",
    "    \n",
    "    df ---> A pandas DataFrame\n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    db_cols --> a dictionary with column-name as key and SQL-Alchemy\n",
    "                data type as values.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    col_info = dict(df.dtypes)\n",
    "    db_cols = {}\n",
    "    for k in col_info:\n",
    "\n",
    "        if col_info[k] == 'object':\n",
    "            db_cols[k] = String\n",
    "\n",
    "        elif col_info[k] == 'int64':\n",
    "            db_cols[k] = Integer\n",
    "\n",
    "        elif col_info[k] == 'float64':\n",
    "            db_cols[k] = Float  \n",
    "        elif col_info[k] == 'string':\n",
    "            db_cols[k] = String   \n",
    "        elif col_info[k] == 'datetime':\n",
    "            db_cols[k] = DateTime\n",
    "        else:\n",
    "            print('Unaccounted for type:')\n",
    "            print(k, col_info[k])\n",
    "            return None\n",
    "    return db_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_file_as_df(data_file_path, file_name):\n",
    "    #print('loading csv into a df', data_file_path, file_name)\n",
    "    df = pd.read_csv(data_file_path+file_name)\n",
    "    \n",
    "    new_columns = [column.replace(' ', '_').lower() for column in df]\n",
    "    df.columns = new_columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(data_file_path, file_name_pattern):\n",
    "#     print(\"getting the file names..\")\n",
    "    all_file_list = os.listdir(data_file_path)\n",
    "\n",
    "    all_file_list.sort()\n",
    "    #print(len(all_file_list))\n",
    "    \n",
    "    file_list = []\n",
    "\n",
    "    for f in all_file_list:\n",
    "        \n",
    "        if file_name_pattern in f:\n",
    "            file_list.append(f)\n",
    "       \n",
    "    return  file_list       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col_types(df, col_type_dict):\n",
    "    \n",
    "    print('set_col_types start')\n",
    "    \n",
    "    for col in list(df.columns):\n",
    "        \n",
    "        try:\n",
    "       \n",
    "            if col_type_dict[col] == 'string':\n",
    "             #   print('got a string', col)\n",
    "                df[col].fillna('', inplace=True)\n",
    "                df[col] = df[col].astype(str)\n",
    "                continue\n",
    "            if col_type_dict[col] == 'int':\n",
    "              #  print('got an int', col)\n",
    "                df[col].fillna(0, inplace=True)\n",
    "                df[col] = df[col].astype(int)\n",
    "                continue\n",
    "            if col_type_dict[col] == 'float':\n",
    "               # print('got a float', col)\n",
    "                df[col].fillna(0.0, inplace=True)\n",
    "                df[col] = df[col].astype(float)\n",
    "                continue\n",
    "            if col_type_dict[col] == 'datetime':\n",
    "                df[col].fillna(19990101, inplace=True)\n",
    "\n",
    "                df[col] = pd.to_datetime(df[col], format='%Y-%m-%d').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "            else:\n",
    "                raise TypeError('no condition for this type: ', col, col_type_dict[col] )\n",
    "        except:\n",
    "            print(col, col_type_dict[col] )\n",
    "            raise\n",
    "            \n",
    "    print('set_col_types end')   \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_csv_data_to_db(filename_pattern_and_tablename_dict, data_file_path, col_type_dict):\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    current_pattern = ''\n",
    "    last_file = ''\n",
    "    total_files = 0\n",
    "    loaded_files = []\n",
    "   # print('outside first for')\n",
    "    # 1. iterate through list of patterns, to load all file-types into the database.\n",
    "    for pattern in filename_pattern_and_tablename_dict.keys():\n",
    "        \n",
    "        print('complete:', current_pattern, 'total number of files:', total_files)\n",
    "        print('last_file', last_file)\n",
    "        current_pattern = pattern\n",
    "        # 2. Get the list of files from the data-folder:\n",
    "        data_file_list = get_file_names(data_file_path, pattern)\n",
    "                  \n",
    "        table_name = filename_pattern_and_tablename_dict[pattern]\n",
    "                \n",
    "        # 3. load data into a data frame\n",
    "        file_counter = 1\n",
    "       # print('in first loop, outside second.. ')\n",
    "        for data_file in data_file_list:\n",
    "            last_file = data_file\n",
    "            if data_file not in loaded_files:\n",
    "                loaded_files.append(data_file)\n",
    "#             print('top of second loop.')\n",
    "            df = load_csv_file_as_df(data_file_path, data_file)\n",
    "    \n",
    "            df = set_col_types(df, col_type_dict)\n",
    "\n",
    "            # Get the columns data types from the data frame and convert \n",
    "            # to SQL-Alchemy friend types.\n",
    "\n",
    "            db_cols = get_db_cols(df)\n",
    "            \n",
    "#             if db_cols == None:\n",
    "                \n",
    "#                 print(data_file, f)\n",
    "#                 return None\n",
    "\n",
    "            if file_counter == 1:\n",
    "                            \n",
    "                df.to_sql(table_name,\n",
    "                                   db_engine,\n",
    "                                   if_exists='replace',\n",
    "                                schema='public',\n",
    "                                   index=False,\n",
    "                                   chunksize=1000,\n",
    "                                   dtype=db_cols)            \n",
    "                print('if counter = 1', data_file)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                try:\n",
    "                    df.to_sql(table_name,\n",
    "                                       db_engine,\n",
    "                                       if_exists='append',\n",
    "                                       schema='public',\n",
    "                                       index=False,\n",
    "                                       chunksize=1000,\n",
    "                                       dtype=db_cols)\n",
    "                    print('going through the list.. ', data_file)\n",
    "                except:\n",
    "                    raise()\n",
    "                    print('skipped this file: ', data_file)\n",
    "                    continue\n",
    "            file_counter += 1\n",
    "            total_files = file_counter\n",
    "    return loaded_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_type = 'postgres'\n",
    "db_lib = 'psycopg2'\n",
    "user_id = 'bhima'\n",
    "password= ''\n",
    "db_name = 'openfda'\n",
    "\n",
    "db_URI = build_DB_URI(db_type, db_lib, user_id, password, db_name)\n",
    "db_engine = create_engine(db_URI, echo=False)\n",
    "db_engine.connect()\n",
    "connection= db_engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_col_types ={\n",
    "    'safetyreportid': 'string',\n",
    "'authoritynumb': 'string',\n",
    "'companynumb': 'string',\n",
    "'duplicate': 'string',\n",
    "'fulfillexpeditecriteria': 'int',\n",
    "'occurcountry': 'string',\n",
    "'patient_patientagegroup': 'string',\n",
    "'patient_patientonsetage': 'float',\n",
    "'patient_patientonsetageunit': 'float',\n",
    "'patient_patientsex': 'int',\n",
    "'patient_patientweight': 'float',\n",
    "'patient_summary_narrativeincludeclinical': 'string',\n",
    "'primarysource_literaturereference': 'string',\n",
    "'primarysource_qualification': 'float',\n",
    "'primarysource_reportercountry': 'string',\n",
    "'primarysourcecountry': 'string',\n",
    "'receiptdate': 'datetime',\n",
    "'receiptdateformat': 'int',\n",
    "'receivedate': 'datetime',\n",
    "'receivedateformat': 'int',\n",
    "'receiver_receiverorganization': 'string',\n",
    "'receiver_receivertype': 'float',\n",
    "'reporttype': 'float',\n",
    "'safetyreportversion': 'float',\n",
    "'sender_senderorganization': 'string',\n",
    "'sender_sendertype': 'float',\n",
    "'serious': 'int',\n",
    "'seriousnesscongenitalanomali': 'float',\n",
    "'seriousnessdeath': 'float',\n",
    "'seriousnessdisabling': 'float',\n",
    "'seriousnesshospitalization': 'float',\n",
    "'seriousnesslifethreatening': 'float',\n",
    "'seriousnessother': 'float',\n",
    "'transmissiondate': 'datetime',\n",
    "'transmissiondateformat': 'int'}\n",
    "\n",
    "####\n",
    "reactions_col_types = {'receiptdate': 'datetime',\n",
    "'safetyreportid': 'string',\n",
    "'reactionmeddrapt': 'string',\n",
    "'reactionmeddraversionpt': 'float',\n",
    "'reactionoutcome': 'float'}\n",
    "\n",
    "###\n",
    "drugs_col_types = {'receiptdate': 'datetime',\n",
    "'safetyreportid': 'string',\n",
    "'actiondrug': 'float',\n",
    "'activesubstancename': 'string',\n",
    "'medicinalproduct': 'string',\n",
    "'openfda_md5': 'string',\n",
    "'openfda_brand_name': 'string',\n",
    "'openfda_generic_name': 'string',\n",
    "'drugadditional': 'string',\n",
    "'drugcumulativedosagenumb': 'string',\n",
    "'drugcumulativedosageunit': 'string',\n",
    "'drugdosageform': 'string',\n",
    "'drugintervaldosagedefinition': 'string',\n",
    "'drugintervaldosageunitnumb': 'string',\n",
    "'drugrecurreadministration': 'string',\n",
    "'drugseparatedosagenumb': 'string',\n",
    "'drugstructuredosagenumb': 'string',\n",
    "'drugstructuredosageunit': 'string',\n",
    "'drugadministrationroute': 'string',\n",
    "'drugauthorizationnumb': 'string',\n",
    "'drugbatchnumb': 'string',\n",
    "'drugcharacterization': 'int',\n",
    "'drugdosagetext': 'string',\n",
    "'drugenddate': 'datetime',\n",
    "'drugenddateformat': 'float',\n",
    "'drugindication': 'string',\n",
    "'drugstartdate': 'datetime',\n",
    "'drugstartdateformat': 'float',\n",
    "'drugtreatmentduration': 'string',\n",
    "'drugtreatmentdurationunit': 'string'}\n",
    "\n",
    "###\n",
    "open_fda_col_types = {'openfda_md5' : 'string',\n",
    "'count' : 'int',\n",
    "'openfda_brand_name': 'string',\n",
    "'openfda_generic_name': 'string',\n",
    "'openfda_application_number': 'string',\n",
    "'openfda_dosage_form': 'string',\n",
    "'openfda_manufacturer_name': 'string',\n",
    "'openfda_is_original_packager':'string',\n",
    "'openfda_product_ndc':'string',\n",
    "'openfda_nui':'string',\n",
    "'openfda_package_ndc': 'string',\n",
    "'openfda_product_type': 'string', \n",
    "'openfda_route':'string',\n",
    "'openfda_substance_name':'string',\n",
    "'openfda_spl_id':'string',\n",
    "'openfda_spl_set_id':'string',\n",
    "'openfda_pharm_class_epc':'string',\n",
    "'openfda_pharm_class_moa':'string',\n",
    "'openfda_pharm_class_moa':'string',\n",
    "'openfda_pharm_class_cs':'string',\n",
    "'openfda_pharm_class_pe':'string',\n",
    "'openfda_upc': 'string',\n",
    "'openfda_unii':'string',\n",
    "'openfda_rxcui':'string'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/csv/2012-2015/2012q1_drug-event-0002-of-0002.json.drug.csv\r\n",
      "../Data/csv/2012-2015/2012q1_drug-event-0002-of-0002.json.openfda.csv\r\n",
      "../Data/csv/2012-2015/2012q1_drug-event-0002-of-0002.json.patient.csv\r\n",
      "../Data/csv/2012-2015/2012q1_drug-event-0002-of-0002.json.reaction.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../Data/csv/2012-2015/2012q1_drug-event-0002-of-0002.json.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  total number of files: 0\n",
      "last_file \n",
      "if counter = 1 2012q1_drug-event-0001-of-0002.json.openfda.csv\n",
      "going through the list..  2012q1_drug-event-0002-of-0002.json.openfda.csv\n",
      "going through the list..  2012q2_drug-event-0001-of-0002.json.openfda.csv\n",
      "going through the list..  2012q2_drug-event-0002-of-0002.json.openfda.csv\n",
      "going through the list..  2012q3_drug-event-0001-of-0002.json.openfda.csv\n",
      "going through the list..  2012q3_drug-event-0002-of-0002.json.openfda.csv\n",
      "going through the list..  2012q4_drug-event-0001-of-0003.json.openfda.csv\n",
      "going through the list..  2012q4_drug-event-0002-of-0003.json.openfda.csv\n",
      "going through the list..  2012q4_drug-event-0003-of-0003.json.openfda.csv\n",
      "going through the list..  2013q1_drug-event-0001-of-0003.json.openfda.csv\n",
      "going through the list..  2013q1_drug-event-0002-of-0003.json.openfda.csv\n",
      "going through the list..  2013q1_drug-event-0003-of-0003.json.openfda.csv\n",
      "going through the list..  2013q2_drug-event-0001-of-0003.json.openfda.csv\n",
      "going through the list..  2013q2_drug-event-0002-of-0003.json.openfda.csv\n",
      "going through the list..  2013q2_drug-event-0003-of-0003.json.openfda.csv\n",
      "going through the list..  2013q3_drug-event-0001-of-0003.json.openfda.csv\n",
      "going through the list..  2013q3_drug-event-0002-of-0003.json.openfda.csv\n",
      "going through the list..  2013q3_drug-event-0003-of-0003.json.openfda.csv\n",
      "going through the list..  2013q4_drug-event-0001-of-0003.json.openfda.csv\n",
      "going through the list..  2013q4_drug-event-0002-of-0003.json.openfda.csv\n",
      "going through the list..  2013q4_drug-event-0003-of-0003.json.openfda.csv\n",
      "going through the list..  2014q1_drug-event-0001-of-0003.json.openfda.csv\n",
      "going through the list..  2014q1_drug-event-0002-of-0003.json.openfda.csv\n",
      "going through the list..  2014q1_drug-event-0003-of-0003.json.openfda.csv\n",
      "going through the list..  2014q2_drug-event-0001-of-0003.json.openfda.csv\n",
      "going through the list..  2014q2_drug-event-0002-of-0003.json.openfda.csv\n",
      "going through the list..  2014q2_drug-event-0003-of-0003.json.openfda.csv\n",
      "going through the list..  2014q3_drug-event-0001-of-0003.json.openfda.csv\n",
      "going through the list..  2014q3_drug-event-0002-of-0003.json.openfda.csv\n",
      "going through the list..  2014q3_drug-event-0003-of-0003.json.openfda.csv\n",
      "going through the list..  2014q4_drug-event-0001-of-0003.json.openfda.csv\n",
      "going through the list..  2014q4_drug-event-0002-of-0003.json.openfda.csv\n",
      "going through the list..  2014q4_drug-event-0003-of-0003.json.openfda.csv\n",
      "going through the list..  2015q1_drug-event-0001-of-0004.json.openfda.csv\n",
      "going through the list..  2015q1_drug-event-0002-of-0004.json.openfda.csv\n",
      "going through the list..  2015q1_drug-event-0003-of-0004.json.openfda.csv\n",
      "going through the list..  2015q1_drug-event-0004-of-0004.json.openfda.csv\n",
      "going through the list..  2015q2_drug-event-0001-of-0004.json.openfda.csv\n",
      "going through the list..  2015q2_drug-event-0002-of-0004.json.openfda.csv\n",
      "going through the list..  2015q2_drug-event-0003-of-0004.json.openfda.csv\n",
      "going through the list..  2015q2_drug-event-0004-of-0004.json.openfda.csv\n",
      "going through the list..  2015q3_drug-event-0001-of-0005.json.openfda.csv\n",
      "going through the list..  2015q3_drug-event-0002-of-0005.json.openfda.csv\n",
      "going through the list..  2015q3_drug-event-0003-of-0005.json.openfda.csv\n",
      "going through the list..  2015q3_drug-event-0004-of-0005.json.openfda.csv\n",
      "going through the list..  2015q3_drug-event-0005-of-0005.json.openfda.csv\n",
      "going through the list..  all_other_drug-event-0001-of-0001.json.openfda.csv\n"
     ]
    }
   ],
   "source": [
    "filename_pattern_and_tablename_dict = {'openfda.csv':'open_fda'}\n",
    "#{'patient.csv':'patients', 'reaction.csv':'reactions', 'openfda.csv':'open_fda', 'drug.csv':'drugs'} #{'drug.csv':'drugs', \n",
    "\n",
    "#location of the data files:\n",
    "data_file_path = '../Data/csv/2012-2015/'\n",
    "\n",
    "loaded_files = load_csv_data_to_db(filename_pattern_and_tablename_dict, data_file_path, open_fda_col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  total number of files: 0\n",
      "last_file \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (5,15,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if counter = 1 2012q1_drug-event-0001-of-0002.json.patient.csv\n",
      "going through the list..  2012q1_drug-event-0002-of-0002.json.patient.csv\n",
      "going through the list..  2012q2_drug-event-0001-of-0002.json.patient.csv\n",
      "going through the list..  2012q2_drug-event-0002-of-0002.json.patient.csv\n",
      "going through the list..  2012q3_drug-event-0001-of-0002.json.patient.csv\n",
      "going through the list..  2012q3_drug-event-0002-of-0002.json.patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going through the list..  2012q4_drug-event-0001-of-0003.json.patient.csv\n",
      "going through the list..  2012q4_drug-event-0002-of-0003.json.patient.csv\n",
      "going through the list..  2012q4_drug-event-0003-of-0003.json.patient.csv\n",
      "going through the list..  2013q1_drug-event-0001-of-0003.json.patient.csv\n",
      "going through the list..  2013q1_drug-event-0002-of-0003.json.patient.csv\n",
      "going through the list..  2013q1_drug-event-0003-of-0003.json.patient.csv\n",
      "going through the list..  2013q2_drug-event-0001-of-0003.json.patient.csv\n",
      "going through the list..  2013q2_drug-event-0002-of-0003.json.patient.csv\n",
      "going through the list..  2013q2_drug-event-0003-of-0003.json.patient.csv\n",
      "going through the list..  2013q3_drug-event-0001-of-0003.json.patient.csv\n",
      "going through the list..  2013q3_drug-event-0002-of-0003.json.patient.csv\n",
      "going through the list..  2013q3_drug-event-0003-of-0003.json.patient.csv\n",
      "going through the list..  2013q4_drug-event-0001-of-0003.json.patient.csv\n",
      "going through the list..  2013q4_drug-event-0002-of-0003.json.patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going through the list..  2013q4_drug-event-0003-of-0003.json.patient.csv\n",
      "going through the list..  2014q1_drug-event-0001-of-0003.json.patient.csv\n",
      "going through the list..  2014q1_drug-event-0002-of-0003.json.patient.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (1,11,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going through the list..  2014q1_drug-event-0003-of-0003.json.patient.csv\n",
      "going through the list..  2014q2_drug-event-0001-of-0003.json.patient.csv\n",
      "going through the list..  2014q2_drug-event-0002-of-0003.json.patient.csv\n",
      "going through the list..  2014q2_drug-event-0003-of-0003.json.patient.csv\n",
      "going through the list..  2014q3_drug-event-0001-of-0003.json.patient.csv\n",
      "going through the list..  2014q3_drug-event-0002-of-0003.json.patient.csv\n",
      "going through the list..  2014q3_drug-event-0003-of-0003.json.patient.csv\n",
      "going through the list..  2014q4_drug-event-0001-of-0003.json.patient.csv\n",
      "going through the list..  2014q4_drug-event-0002-of-0003.json.patient.csv\n",
      "going through the list..  2014q4_drug-event-0003-of-0003.json.patient.csv\n",
      "going through the list..  2015q1_drug-event-0001-of-0004.json.patient.csv\n",
      "going through the list..  2015q1_drug-event-0002-of-0004.json.patient.csv\n",
      "going through the list..  2015q1_drug-event-0003-of-0004.json.patient.csv\n",
      "going through the list..  2015q1_drug-event-0004-of-0004.json.patient.csv\n",
      "going through the list..  2015q2_drug-event-0001-of-0004.json.patient.csv\n",
      "going through the list..  2015q2_drug-event-0002-of-0004.json.patient.csv\n",
      "going through the list..  2015q2_drug-event-0003-of-0004.json.patient.csv\n",
      "going through the list..  2015q2_drug-event-0004-of-0004.json.patient.csv\n",
      "going through the list..  2015q3_drug-event-0001-of-0005.json.patient.csv\n",
      "going through the list..  2015q3_drug-event-0002-of-0005.json.patient.csv\n",
      "going through the list..  2015q3_drug-event-0003-of-0005.json.patient.csv\n",
      "going through the list..  2015q3_drug-event-0004-of-0005.json.patient.csv\n",
      "going through the list..  2015q3_drug-event-0005-of-0005.json.patient.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'OutOfBoundsDatetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'int'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-804bda9bf992>\u001b[0m in \u001b[0;36mset_col_types\u001b[0;34m(df, col_type_dict)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%Y%m%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOutOfBoundsDatetime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    399\u001b[0m                     result, timezones = array_strptime(\n\u001b[0;32m--> 400\u001b[0;31m                         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m                     )\n",
      "\u001b[0;32mpandas/_libs/tslibs/strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/np_datetime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 5200-09-26 00:00:00",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c6fa7814c731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../Data/csv/2012-2015/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mloaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv_data_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_pattern_and_tablename_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient_col_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-f33945a68b39>\u001b[0m in \u001b[0;36mload_csv_data_to_db\u001b[0;34m(filename_pattern_and_tablename_dict, data_file_path, col_type_dict)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv_file_as_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_col_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_type_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# Get the columns data types from the data frame and convert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-804bda9bf992>\u001b[0m in \u001b[0;36mset_col_types\u001b[0;34m(df, col_type_dict)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%Y%m%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mOutOfBoundsDatetime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OutOfBoundsDatetime was raised!!!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OutOfBoundsDatetime' is not defined"
     ]
    }
   ],
   "source": [
    "filename_pattern_and_tablename_dict = {'patient.csv':'patients'}\n",
    "#{'patient.csv':'patients', 'reaction.csv':'reactions', 'openfda.csv':'open_fda', 'drug.csv':'drugs'} #{'drug.csv':'drugs', \n",
    "\n",
    "#location of the data files:\n",
    "data_file_path = '../Data/csv/2012-2015/'\n",
    "\n",
    "loaded_files = load_csv_data_to_db(filename_pattern_and_tablename_dict, data_file_path, patient_col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  total number of files: 0\n",
      "last_file \n",
      "if counter = 1 2012q1_drug-event-0001-of-0002.json.reaction.csv\n",
      "going through the list..  2012q1_drug-event-0002-of-0002.json.reaction.csv\n",
      "going through the list..  2012q2_drug-event-0001-of-0002.json.reaction.csv\n",
      "going through the list..  2012q2_drug-event-0002-of-0002.json.reaction.csv\n",
      "going through the list..  2012q3_drug-event-0001-of-0002.json.reaction.csv\n",
      "going through the list..  2012q3_drug-event-0002-of-0002.json.reaction.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going through the list..  2012q4_drug-event-0001-of-0003.json.reaction.csv\n",
      "going through the list..  2012q4_drug-event-0002-of-0003.json.reaction.csv\n",
      "going through the list..  2012q4_drug-event-0003-of-0003.json.reaction.csv\n",
      "going through the list..  2013q1_drug-event-0001-of-0003.json.reaction.csv\n",
      "going through the list..  2013q1_drug-event-0002-of-0003.json.reaction.csv\n",
      "going through the list..  2013q1_drug-event-0003-of-0003.json.reaction.csv\n",
      "going through the list..  2013q2_drug-event-0001-of-0003.json.reaction.csv\n",
      "going through the list..  2013q2_drug-event-0002-of-0003.json.reaction.csv\n",
      "going through the list..  2013q2_drug-event-0003-of-0003.json.reaction.csv\n",
      "going through the list..  2013q3_drug-event-0001-of-0003.json.reaction.csv\n",
      "going through the list..  2013q3_drug-event-0002-of-0003.json.reaction.csv\n",
      "going through the list..  2013q3_drug-event-0003-of-0003.json.reaction.csv\n",
      "going through the list..  2013q4_drug-event-0001-of-0003.json.reaction.csv\n",
      "going through the list..  2013q4_drug-event-0002-of-0003.json.reaction.csv\n",
      "going through the list..  2013q4_drug-event-0003-of-0003.json.reaction.csv\n",
      "going through the list..  2014q1_drug-event-0001-of-0003.json.reaction.csv\n",
      "going through the list..  2014q1_drug-event-0002-of-0003.json.reaction.csv\n",
      "going through the list..  2014q1_drug-event-0003-of-0003.json.reaction.csv\n",
      "going through the list..  2014q2_drug-event-0001-of-0003.json.reaction.csv\n",
      "going through the list..  2014q2_drug-event-0002-of-0003.json.reaction.csv\n",
      "going through the list..  2014q2_drug-event-0003-of-0003.json.reaction.csv\n",
      "going through the list..  2014q3_drug-event-0001-of-0003.json.reaction.csv\n",
      "going through the list..  2014q3_drug-event-0002-of-0003.json.reaction.csv\n",
      "going through the list..  2014q3_drug-event-0003-of-0003.json.reaction.csv\n",
      "going through the list..  2014q4_drug-event-0001-of-0003.json.reaction.csv\n",
      "going through the list..  2014q4_drug-event-0002-of-0003.json.reaction.csv\n",
      "going through the list..  2014q4_drug-event-0003-of-0003.json.reaction.csv\n",
      "going through the list..  2015q1_drug-event-0001-of-0004.json.reaction.csv\n",
      "going through the list..  2015q1_drug-event-0002-of-0004.json.reaction.csv\n",
      "going through the list..  2015q1_drug-event-0003-of-0004.json.reaction.csv\n",
      "going through the list..  2015q1_drug-event-0004-of-0004.json.reaction.csv\n",
      "going through the list..  2015q2_drug-event-0001-of-0004.json.reaction.csv\n",
      "going through the list..  2015q2_drug-event-0002-of-0004.json.reaction.csv\n",
      "going through the list..  2015q2_drug-event-0003-of-0004.json.reaction.csv\n",
      "going through the list..  2015q2_drug-event-0004-of-0004.json.reaction.csv\n",
      "going through the list..  2015q3_drug-event-0001-of-0005.json.reaction.csv\n",
      "going through the list..  2015q3_drug-event-0002-of-0005.json.reaction.csv\n",
      "going through the list..  2015q3_drug-event-0003-of-0005.json.reaction.csv\n",
      "going through the list..  2015q3_drug-event-0004-of-0005.json.reaction.csv\n",
      "going through the list..  2015q3_drug-event-0005-of-0005.json.reaction.csv\n",
      "0         20010221\n",
      "1         20010621\n",
      "2         20030612\n",
      "3         20020314\n",
      "4         20020314\n",
      "            ...   \n",
      "165564    20030124\n",
      "165565    20030124\n",
      "165566    20030124\n",
      "165567    20030124\n",
      "165568    20030325\n",
      "Name: receiptdate, Length: 165569, dtype: int64 raised and exception, at tdatetime.. \n",
      "going through the list..  all_other_drug-event-0001-of-0001.json.reaction.csv\n"
     ]
    }
   ],
   "source": [
    "filename_pattern_and_tablename_dict = {'reaction.csv':'reactions'}\n",
    "#{'patient.csv':'patients', 'reaction.csv':'reactions', 'openfda.csv':'open_fda', 'drug.csv':'drugs'} #{'drug.csv':'drugs', \n",
    "\n",
    "#location of the data files:\n",
    "data_file_path = '../Data/csv/2012-2015/'\n",
    "\n",
    "loaded_files = load_csv_data_to_db(filename_pattern_and_tablename_dict, data_file_path, reactions_col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete:  total number of files: 0\n",
      "last_file \n",
      "set_col_types start\n",
      "set_col_types end\n",
      "if counter = 1 2012q1_drug-event-0001-of-0002.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2012q1_drug-event-0002-of-0002.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2012q2_drug-event-0001-of-0002.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2012q2_drug-event-0002-of-0002.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2012q3_drug-event-0001-of-0002.json.drug.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2012q3_drug-event-0002-of-0002.json.drug.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (1,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2012q4_drug-event-0001-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2012q4_drug-event-0002-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2012q4_drug-event-0003-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2013q1_drug-event-0001-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2013q1_drug-event-0002-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2013q1_drug-event-0003-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2013q2_drug-event-0001-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2013q2_drug-event-0002-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2013q2_drug-event-0003-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2013q3_drug-event-0001-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2013q3_drug-event-0002-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2013q3_drug-event-0003-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2013q4_drug-event-0001-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2013q4_drug-event-0002-of-0003.json.drug.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (3,16,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2013q4_drug-event-0003-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2014q1_drug-event-0001-of-0003.json.drug.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (16,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2014q1_drug-event-0002-of-0003.json.drug.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (3,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2014q1_drug-event-0003-of-0003.json.drug.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (19,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2014q2_drug-event-0001-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2014q2_drug-event-0002-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2014q2_drug-event-0003-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2014q3_drug-event-0001-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2014q3_drug-event-0002-of-0003.json.drug.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (16,19,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2014q3_drug-event-0003-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2014q4_drug-event-0001-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2014q4_drug-event-0002-of-0003.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2014q4_drug-event-0003-of-0003.json.drug.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (6,7,16,19,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q1_drug-event-0001-of-0004.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q1_drug-event-0002-of-0004.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q1_drug-event-0003-of-0004.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q1_drug-event-0004-of-0004.json.drug.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (6,7,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q2_drug-event-0001-of-0004.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q2_drug-event-0002-of-0004.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q2_drug-event-0003-of-0004.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q2_drug-event-0004-of-0004.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q3_drug-event-0001-of-0005.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q3_drug-event-0002-of-0005.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q3_drug-event-0003-of-0005.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q3_drug-event-0004-of-0005.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  2015q3_drug-event-0005-of-0005.json.drug.csv\n",
      "set_col_types start\n",
      "set_col_types end\n",
      "going through the list..  all_other_drug-event-0001-of-0001.json.drug.csv\n"
     ]
    }
   ],
   "source": [
    "filename_pattern_and_tablename_dict = {'drug.csv':'drugs'}\n",
    "#{'patient.csv':'patients', 'reaction.csv':'reactions', 'openfda.csv':'open_fda', 'drug.csv':'drugs'} #{'drug.csv':'drugs', \n",
    "\n",
    "#location of the data files:\n",
    "data_file_path = '../Data/csv/2012-2015/'\n",
    "\n",
    "loaded_files = load_csv_data_to_db(filename_pattern_and_tablename_dict, data_file_path, drugs_col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_file_path = '../Data/csv/SelectedData/'\n",
    "data_file = '2008q2_drug-event-0001-of-0002.json.openfda.csv'\n",
    "df = load_csv_file_as_df(data_file_path, data_file)\n",
    "df = clean_up_column_values(df)\n",
    "\n",
    "!ls ../Data/csv/SelectedData/2008q2_drug-event-0001-of-0002.json.openfda.csv\n",
    "\n",
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def clean_up_column_values(df, set_max_val=True, max_unique_col_vals=99):\n",
    "    '''\n",
    "    A method that aims to clean up columns in a data frame. When importing data from\n",
    "    a CSV sometimes NaN values are put in empty spaces of a column containing strings.\n",
    "    \n",
    "    Args:\n",
    "    ======\n",
    "    \n",
    "    df                    --> the data frame which needs values to be cleaned up.\n",
    "    \n",
    "    set_max_val           --> a boolean which allows the user to decide if they want to go\n",
    "                              through all unique values in a column.\n",
    "                              \n",
    "    max_unique_col_values --> some columns have many unique values and it would take a\n",
    "                              long time to check every value, so there is an option. \n",
    "                              \n",
    "   Returns:\n",
    "   ========\n",
    "   \n",
    "   df                    --> the data frame which has been cleaned up.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for col in list(df.columns):\n",
    "\n",
    "        print('before', col, df[col].dtype)\n",
    "        #if df[col].dtype == 'object':\n",
    "\n",
    "\n",
    "        vals = pd.unique(df[col])\n",
    "        print('these are the unique values:')\n",
    "        print(vals)\n",
    "        col_dtype = np.nan\n",
    "\n",
    "\n",
    "        if set_max_val and len(vals) > max_unique_col_vals:\n",
    "            continue\n",
    "\n",
    "        for v in vals:\n",
    "            if col_dtype != np.nan:\n",
    "                col_dtype = type(v)\n",
    "            elif col_dytpe != type(v):\n",
    "                raise TypeError(\"There are several data-types in this column:\", col, vals, val_type)      \n",
    "\n",
    "        if col_dtype == str:\n",
    "            #print('got a string', col)\n",
    "            df[col].fillna('', inplace=True)\n",
    "            df[col] = df[col].astype(str)\n",
    "        if col_dtype == 'int64':\n",
    "            print('got an int', col)\n",
    "            df[col].fillna(0, inplace=True)\n",
    "            df[col] = df[col].astype(int)\n",
    "        if col_dtype == 'float64':\n",
    "            print('got a float', col)\n",
    "            df[col].fillna(0.0, inplace=True)\n",
    "            df[col] = df[col].astype(float)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_file = '2012q1_drug-event-0002-of-0002.json.drug.csv'\n",
    "drugs_col_types = {}\n",
    "drug_df = load_csv_file_as_df(data_file_path, drug_file)\n",
    "\n",
    "for col in list(drug_df.columns):\n",
    "\n",
    "    print(col,' || ', drug_df[col].dtype, ' || ', pd.unique(drug_df[col]))\n",
    "    drugs_col_types[col] = drug_df[col].dtype\n",
    "    \n",
    "print('=========================')\n",
    "for key in drugs_col_types:\n",
    "    print(\"'\"+key+\"':\", \"'\"+str(drugs_col_types[key])+\"'\")\n",
    "\n",
    "drugs_col_types = {'receiptdate': 'datetime'\n",
    "'safetyreportid': 'string'\n",
    "'actiondrug': 'float'\n",
    "'activesubstancename': 'string'\n",
    "'medicinalproduct': 'string'\n",
    "'openfda_md5': 'string'\n",
    "'openfda_brand_name': 'string'\n",
    "'openfda_generic_name': 'string'\n",
    "'drugadditional': 'string'\n",
    "'drugcumulativedosagenumb': 'string'\n",
    "'drugcumulativedosageunit': 'string'\n",
    "'drugdosageform': 'string'\n",
    "'drugintervaldosagedefinition': 'float'\n",
    "'drugintervaldosageunitnumb': 'float'\n",
    "'drugrecurreadministration': 'float'\n",
    "'drugseparatedosagenumb': 'float'\n",
    "'drugstructuredosagenumb': 'float'\n",
    "'drugstructuredosageunit': 'float'\n",
    "'drugadministrationroute': 'float'\n",
    "'drugauthorizationnumb': 'float'\n",
    "'drugbatchnumb': 'string'\n",
    "'drugcharacterization': 'int'\n",
    "'drugdosagetext': 'string'\n",
    "'drugenddate': 'datetime'\n",
    "'drugenddateformat': 'float'\n",
    "'drugindication': 'string'\n",
    "'drugstartdate': 'datetime'\n",
    "'drugstartdateformat': 'float'\n",
    "'drugtreatmentduration': 'float'\n",
    "'drugtreatmentdurationunit': 'float'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_file = '2012q1_drug-event-0002-of-0002.json.reaction.csv'\n",
    "reactions_col_types = {}\n",
    "reaction_df = load_csv_file_as_df(data_file_path, reaction_file)\n",
    "\n",
    "for col in list(reaction_df.columns):\n",
    "\n",
    "    print(col,' || ', reaction_df[col].dtype, ' || ', pd.unique(reaction_df[col]))\n",
    "    reactions_col_types[col] = reaction_df[col].dtype\n",
    "    \n",
    "print('=========================')\n",
    "for key in reactions_col_types:\n",
    "    print(\"'\"+key+\"':\", \"'\"+str(reactions_col_types[key])+\"'\")\n",
    "\n",
    "\n",
    "reaction_df\n",
    "\n",
    "reactions_col_types ={'receiptdate': 'datetime'\n",
    "'safetyreportid': 'string'\n",
    "'reactionmeddrapt': 'string'\n",
    "'reactionmeddraversionpt': 'float'\n",
    "'reactionoutcome': 'float'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = '../Data/csv/2012-2015/''\n",
    "\n",
    "patient_file = '2012q1_drug-event-0002-of-0002.json.patient.csv'\n",
    "patients_col_types = {}\n",
    "patient_df = load_csv_file_as_df(data_file_path, patient_file)\n",
    "\n",
    "for col in list(patient_df.columns):\n",
    "\n",
    "    print(col,' || ', patient_df[col].dtype, ' || ', pd.unique(patient_df[col]))\n",
    "    patients_col_types[col] = patient_df[col].dtype\n",
    "    \n",
    "print('=========================')\n",
    "for key in patients_col_types:\n",
    "    print(\"'\"+key+\"':\", \"'\"+str(patients_col_types[key])+\"'\")\n",
    "\n",
    "patient_df.transmissiondate.unique()\n",
    "\n",
    "patient_col_types ={\n",
    "    'safetyreportid': 'string'\n",
    "'authoritynumb': 'string'\n",
    "'companynumb': 'string'\n",
    "'duplicate': 'string'\n",
    "'fulfillexpeditecriteria': 'int'\n",
    "'occurcountry': 'string'\n",
    "'patient_patientagegroup': 'string'\n",
    "'patient_patientonsetage': 'float'\n",
    "'patient_patientonsetageunit': 'float'\n",
    "'patient_patientsex': 'int'\n",
    "'patient_patientweight': 'float'\n",
    "'patient_summary_narrativeincludeclinical': 'string'\n",
    "'primarysource_literaturereference': 'string'\n",
    "'primarysource_qualification': 'float'\n",
    "'primarysource_reportercountry': 'string'\n",
    "'primarysourcecountry': 'string'\n",
    "'receiptdate': 'datetime'\n",
    "'receiptdateformat': 'int'\n",
    "'receivedate': 'datetime'\n",
    "'receivedateformat': 'int'\n",
    "'receiver_receiverorganization': 'string'\n",
    "'receiver_receivertype': 'float'\n",
    "'reporttype': 'float'\n",
    "'safetyreportversion': 'float'\n",
    "'sender_senderorganization': 'string'\n",
    "'sender_sendertype': 'float'\n",
    "'serious': 'int'\n",
    "'seriousnesscongenitalanomali': 'float'\n",
    "'seriousnessdeath': 'float'\n",
    "'seriousnessdisabling': 'float'\n",
    "'seriousnesshospitalization': 'float'\n",
    "'seriousnesslifethreatening': 'float'\n",
    "'seriousnessother': 'float'\n",
    "'transmissiondate': 'datetime'\n",
    "'transmissiondateformat': 'int'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_df['receiptdate'] = pd.to_datetime(patient_df['receiptdate'], format='%Y%m%d').dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "patient_df[['receiptdate','receiptdate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!/opt/anaconda3/bin/conda install pandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
